[DEFAULT]

[1]
epochs = 10
prefix_max_new_tokens = 5
text_max_new_tokens = 5

[2]
epochs = 10
prefix_max_new_tokens = 5
text_max_new_tokens = 10

[3]
epochs = 10
prefix_max_new_tokens = 5
text_max_new_tokens = 10
entropy_coef = 1e-3

[4]
epochs = 10
prefix_max_new_tokens = 5
text_max_new_tokens = 10
entropy_coef = 1e-3
target = 0

[5]
epochs = 20
prefix_max_new_tokens = 5
text_max_new_tokens = 10
entropy_coef = 1e-3

[6]
epochs = 10
prefix_max_new_tokens = 5
text_max_new_tokens = 20
entropy_coef = 1e-3
debug = False

[7]
epochs = 10
prefix_max_new_tokens = 5
text_max_new_tokens = 20
entropy_coef = 1e-3
resume_id = 7ure2edv
debug = False

[8]
epochs = 1
prefix_max_new_tokens = 5
text_max_new_tokens = 20
entropy_coef = 1e-3
debug = False

[9]
epochs = 2
prefix_max_new_tokens = 5
text_max_new_tokens = 20
entropy_coef = 1e-3
debug = False
dataset = imdb_sst2

[10]
epochs = 2
prefix_max_new_tokens = 5
text_max_new_tokens = 20
entropy_coef = 1e-1
learning_rate = 1e-6
debug = False
dataset = imdb_sst2

[11]
epochs = 2
prefix_max_new_tokens = 5
text_max_new_tokens = 20
entropy_coef = 1e-3
learning_rate = 1.41e-6
debug = False
dataset = imdb_sst2
batch_size = 256
mini_batch_size = 32
ratio_threshold = 5

[12]
epochs = 8
prefix_max_new_tokens = 5
text_max_new_tokens = 20
entropy_coef = 1e-3
learning_rate = 1.41e-6
debug = False
dataset = imdb_sst2
batch_size = 256
mini_batch_size = 32
ratio_threshold = 5
resume_id = gilss6fm

[13]
epochs = 5
prefix_max_new_tokens = 10
text_max_new_tokens = 20
entropy_coef = 1e-3
learning_rate = 1.41e-6
debug = False
dataset = imdb_sst2
batch_size = 256
mini_batch_size = 32
ratio_threshold = 5

[14]
epochs = 5
prefix_max_new_tokens = 10
text_max_new_tokens = 20
entropy_coef = 1e-3
learning_rate = 1.41e-6
debug = False
dataset = imdb_sst2
batch_size = 256
mini_batch_size = 32
ratio_threshold = 5
reward_model = gpt2-large